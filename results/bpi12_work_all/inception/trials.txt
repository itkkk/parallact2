
Fold: 0
Hyperopt trials
tid, loss, learning_rate, batch_size, cells, dropout, LSTMLayers, train_time
0,0.271827,0.000155,0,349.816296
1,0.255461,0.001067,0,290.324646
2,0.259587,0.000223,1,308.436245
3,0.272472,0.000200,0,341.972482
4,0.269660,0.000046,1,399.176823
5,0.255022,0.000619,0,477.645627
6,0.255866,0.000454,1,285.413521
7,0.266487,0.001110,1,160.173156
8,0.267976,0.000381,0,333.331170
9,0.261781,0.000191,2,297.972829
10,0.266554,0.000047,2,393.800819
11,0.284514,0.000012,2,512.383473
12,0.276177,0.000123,1,238.061027
13,0.266632,0.000703,2,106.073560
14,0.277358,0.000014,1,577.066718
15,0.253999,0.000355,0,413.909063
16,0.276831,0.000026,2,393.765719
17,0.262404,0.002511,1,107.010774
18,0.256813,0.009975,2,59.133110
19,0.262006,0.003866,0,265.513454
20,0.255753,0.002447,0,249.463160
21,0.258901,0.000098,0,560.690841
22,0.263651,0.006563,0,215.691316
23,0.253008,0.000698,0,440.186993
24,0.258729,0.001485,0,276.611691
25,0.264835,0.000071,0,561.216844
26,0.257425,0.000288,0,542.647236
27,0.255370,0.000651,0,342.406977
28,0.263284,0.001855,0,274.379653
29,0.262446,0.004153,0,213.352303

Best parameters:{'batch_size': 128, 'learning_rate_init': 0.0006984459972829054, 'n_modules': 2}

Fold: 1
Hyperopt trials
tid, loss, learning_rate, batch_size, cells, dropout, LSTMLayers, train_time
0,0.253368,0.007149,2,45.125454
1,0.280282,0.000015,1,513.822861
2,0.246776,0.000410,1,284.410772
3,0.247733,0.001802,1,203.703373
4,0.258099,0.000040,2,385.348071
5,0.257298,0.000083,1,347.472322
6,0.251902,0.004585,0,220.293845
7,0.279238,0.000031,2,298.899622
8,0.275925,0.000035,0,564.475463
9,0.252719,0.000160,0,374.790171
10,0.261555,0.000305,0,264.342314
11,0.247008,0.000667,2,236.119476
12,0.264037,0.000040,2,315.014033
13,0.256425,0.000089,1,349.059553
14,0.250803,0.000095,0,514.886956
15,0.248621,0.000098,1,517.162982
16,0.272914,0.000013,2,518.058457
17,0.275474,0.000030,0,612.407485
18,0.266848,0.000023,2,416.640746
19,0.249029,0.000151,0,600.214300
20,0.247232,0.001050,1,246.021599
21,0.246793,0.000751,1,245.626962
22,0.248641,0.002179,1,157.005447
23,0.246993,0.000407,1,310.070865
24,0.247195,0.000450,1,258.683678
25,0.249650,0.001159,1,176.679587
26,0.255799,0.003246,1,176.812141
27,0.248570,0.000240,1,301.352135
28,0.256825,0.009985,1,204.090053
29,0.246893,0.000688,1,284.105487

Best parameters:{'batch_size': 256, 'learning_rate_init': 0.0004095170840560279, 'n_modules': 3}

Fold: 2
Hyperopt trials
tid, loss, learning_rate, batch_size, cells, dropout, LSTMLayers, train_time
0,0.307252,0.000010,2,309.583693
1,0.272814,0.000281,2,117.490116
2,0.279969,0.000055,0,701.515657
3,0.262879,0.000029,0,849.767324
4,0.261541,0.000106,2,204.589163
5,0.269928,0.000040,2,327.449478
6,0.253830,0.000172,2,327.434577
7,0.254971,0.001293,0,299.278278
8,0.281438,0.000028,1,512.557435
9,0.258018,0.000241,2,202.015044
10,0.262727,0.000063,2,325.517454
11,0.259960,0.001804,0,226.066054
12,0.258934,0.003051,1,98.292608
13,0.257369,0.001687,2,181.941654
14,0.263970,0.000646,0,290.612768
15,0.262922,0.001726,1,157.241423
16,0.260928,0.000190,1,259.228452
17,0.310265,0.000010,2,307.978653
18,0.273754,0.000015,2,621.206059
19,0.268408,0.000098,0,456.979782
20,0.262554,0.008008,0,341.957840
21,0.250731,0.000617,0,368.859330
22,0.253873,0.000548,0,402.910670
23,0.251902,0.000520,0,451.663746
24,0.251442,0.000558,0,368.483652
25,0.257263,0.004074,0,222.030616
26,0.252568,0.001014,0,366.254262
27,0.260942,0.009958,0,215.904063
28,0.251949,0.000431,0,486.518388
29,0.251970,0.000905,0,378.054765

Best parameters:{'batch_size': 128, 'learning_rate_init': 0.0006174814884267108, 'n_modules': 2}
